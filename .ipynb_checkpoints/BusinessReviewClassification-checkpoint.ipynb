{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of Business Reviews\n",
    "\n",
    "**Author: TanVir Hossain**\n",
    "\n",
    "**Email: hossain.tanvir.m@gmail.com**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code reads business reviews which are part of the [Yelp Dataset stored in Kaggle](https://www.kaggle.com/yelp-dataset/yelp-dataset). Dataset is not provided because it is really big (1.5GB). You have to download it separately. The data are stored in a CSV file. The following code reads the CSV file and prints the contents of the first 5 records:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vkVSCC7xljjrAI4UGfnKEQ</td>\n",
       "      <td>bv2nCi5Qv5vroFiqKGopiw</td>\n",
       "      <td>AEx2SYEUJmTxVVB18LlCwA</td>\n",
       "      <td>5</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>Super simple place but amazing nonetheless. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n6QzIUObkYshz4dz2QRJTw</td>\n",
       "      <td>bv2nCi5Qv5vroFiqKGopiw</td>\n",
       "      <td>VR6GpWIda3SfvPC-lg9H3w</td>\n",
       "      <td>5</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>Small unassuming place that changes their menu...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MV3CcKScW05u5LVfF6ok0g</td>\n",
       "      <td>bv2nCi5Qv5vroFiqKGopiw</td>\n",
       "      <td>CKC0-MOWMqoeWf6s-szl8g</td>\n",
       "      <td>5</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>Lester's is located in a beautiful neighborhoo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IXvOzsEMYtiJI0CARmj77Q</td>\n",
       "      <td>bv2nCi5Qv5vroFiqKGopiw</td>\n",
       "      <td>ACFtxLv8pGrrxMm6EgjreA</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>Love coming here. Yes the place always needs t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L_9BTb55X0GDtThi6GlZ6w</td>\n",
       "      <td>bv2nCi5Qv5vroFiqKGopiw</td>\n",
       "      <td>s2I_Ni76bjJNK9yG60iD-Q</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>Had their chocolate almond croissant and it wa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id  \\\n",
       "0  vkVSCC7xljjrAI4UGfnKEQ  bv2nCi5Qv5vroFiqKGopiw  AEx2SYEUJmTxVVB18LlCwA   \n",
       "1  n6QzIUObkYshz4dz2QRJTw  bv2nCi5Qv5vroFiqKGopiw  VR6GpWIda3SfvPC-lg9H3w   \n",
       "2  MV3CcKScW05u5LVfF6ok0g  bv2nCi5Qv5vroFiqKGopiw  CKC0-MOWMqoeWf6s-szl8g   \n",
       "3  IXvOzsEMYtiJI0CARmj77Q  bv2nCi5Qv5vroFiqKGopiw  ACFtxLv8pGrrxMm6EgjreA   \n",
       "4  L_9BTb55X0GDtThi6GlZ6w  bv2nCi5Qv5vroFiqKGopiw  s2I_Ni76bjJNK9yG60iD-Q   \n",
       "\n",
       "   stars        date                                               text  \\\n",
       "0      5  2016-05-28  Super simple place but amazing nonetheless. It...   \n",
       "1      5  2016-05-28  Small unassuming place that changes their menu...   \n",
       "2      5  2016-05-28  Lester's is located in a beautiful neighborhoo...   \n",
       "3      4  2016-05-28  Love coming here. Yes the place always needs t...   \n",
       "4      4  2016-05-28  Had their chocolate almond croissant and it wa...   \n",
       "\n",
       "   useful  funny  cool  \n",
       "0       0      0     0  \n",
       "1       0      0     0  \n",
       "2       0      0     0  \n",
       "3       0      0     0  \n",
       "4       0      0     0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd_data = pd.read_csv('yelp_review.zip')\n",
    "pd_data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the data, we will only use the reviews and the star rating. The following code extracts this information and places it in a list of pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = list(zip(pd_data['text'], pd_data['stars']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5261668"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"Super simple place but amazing nonetheless. It's been around since the 30's and they still serve the same thing they started with: a bologna and salami sandwich with mustard. \\n\\nStaff was very helpful and friendly.\",\n",
       "  5),\n",
       " (\"Small unassuming place that changes their menu every so often. Cool decor and vibe inside their 30 seat restaurant. Call for a reservation. \\n\\nWe had their beef tartar and pork belly to start and a salmon dish and lamb meal for mains. Everything was incredible! I could go on at length about how all the listed ingredients really make their dishes amazing but honestly you just need to go. \\n\\nA bit outside of downtown montreal but take the metro out and it's less than a 10 minute walk from the station.\",\n",
       "  5),\n",
       " (\"Lester's is located in a beautiful neighborhood and has been there since 1951. They are known for smoked meat which most deli's have but their brisket sandwich is what I come to montreal for. They've got about 12 seats outside to go along with the inside. \\n\\nThe smoked meat is up there in quality and taste with Schwartz's and you'll find less tourists at Lester's as well.\",\n",
       "  5),\n",
       " (\"Love coming here. Yes the place always needs the floor swept but when you give out  peanuts in the shell how won't it always be a bit dirty. \\n\\nThe food speaks for itself, so good. Burgers are made to order and the meat is put on the grill when you order your sandwich. Getting the small burger just means 1 patty, the regular is a 2 patty burger which is twice the deliciousness. \\n\\nGetting the Cajun fries adds a bit of spice to them and whatever size you order they always throw more fries (a lot more fries) into the bag.\",\n",
       "  4),\n",
       " (\"Had their chocolate almond croissant and it was amazing! So light and buttery and oh my how chocolaty.\\n\\nIf you're looking for a light breakfast then head out here. Perfect spot for a coffee\\\\/latté before heading out to the old port\",\n",
       "  4)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now check the distribution of star ratings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 731363, 2: 438161, 3: 615481, 4: 1223316, 5: 2253347})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "c = Counter([rating for text, rating in all_data])\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Container object of 5 artists>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c1c7aee358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(range(1,6), [c[1], c[2], c[3], c[4], c[5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this project, we will predict whether a particular review gives 5 stars or not.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set is fairly large with more than 5 million samples. To speed up the computations, we will use 500,000 samples for training,  10,000 for the dev-test set and 10,000 for the test set. To reduce any possible bias while partitioning the data set, we will first shuffle the data and then partition into training data, dev-test data, and test data using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(1234)\n",
    "random.shuffle(all_data)\n",
    "train_data, devtest_data, test_data = all_data[:500000], all_data[500000:510000], all_data[510000:520000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1\n",
    "The data are annotated with a star rating. In this project we will attempt to predict whether the review has 5 stars or not. In other words, we will use two categories: \"it does not have 5 stars\", and \"it has 5 stars\". According to these categories, check that the training data, devtest data and test data have the same proportions of the categories \"it does not have 5 stars\", and \"it has 5 stars\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stars_cat (data_input, data_output):\n",
    "    for x in data_input:\n",
    "        if (x[1]==5):\n",
    "            data_output.append((x[0], \"it has 5 stars\"))\n",
    "        else:\n",
    "            data_output.append((x[0], \"it does not have 5 stars\"))\n",
    "    return\n",
    "\n",
    "def count_5 (data_input):\n",
    "    count = 0\n",
    "    for x in data_input:\n",
    "        if (x[1]==\"it has 5 stars\"):\n",
    "            count = count + 1\n",
    "    return count\n",
    "\n",
    "def count_non_5 (data_input):\n",
    "    count = 0\n",
    "    for x in data_input:\n",
    "        if (x[1]==\"it does not have 5 stars\"):\n",
    "            count = count + 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_x = []\n",
    "devtest_data_x = []\n",
    "test_data_x = []\n",
    "\n",
    "stars_cat(train_data, train_data_x)\n",
    "stars_cat(devtest_data, devtest_data_x)\n",
    "stars_cat(test_data, test_data_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data\n",
      "it has 5 stars: 0.42841\n",
      "it does not have 5 stars: 0.57159\n",
      "\n",
      "Dev-test Data\n",
      "it has 5 stars: 0.4275\n",
      "it does not have 5 stars: 0.5725\n",
      "\n",
      "Test Data\n",
      "it has 5 stars: 0.4324\n",
      "it does not have 5 stars: 0.5676\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Data\")\n",
    "print(\"it has 5 stars: \"+str(count_5(train_data_x)/len(train_data_x)))\n",
    "print(\"it does not have 5 stars: \"+str(count_non_5(train_data_x)/len(train_data_x)))\n",
    "\n",
    "\n",
    "print(\"\\nDev-test Data\")\n",
    "print(\"it has 5 stars: \"+str(count_5(devtest_data_x)/len(devtest_data_x)))\n",
    "print(\"it does not have 5 stars: \"+str(count_non_5(devtest_data_x)/len(devtest_data_x)))\n",
    "\n",
    "\n",
    "print(\"\\nTest Data\")\n",
    "print(\"it has 5 stars: \"+str(count_5(test_data_x)/len(test_data_x)))\n",
    "print(\"it does not have 5 stars: \"+str(count_non_5(test_data_x)/len(test_data_x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2\n",
    "Use sklearn to generate the tf.idf matrix of the training set. With this matrix, train an sklearn Naive Bayes classifier using the training set and report the F1 scores of the training set, the devtest set, and the set set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TFIDF\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "train_data_tfidf = tfidf.fit_transform([x for x, y in train_data_x])\n",
    "devtest_data_tfidf = tfidf.transform([x for x, y in devtest_data_x])\n",
    "test_data_tfidf = tfidf.transform([x for x, y in test_data_x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Naive Bayes\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "naive_bayes = MultinomialNB()\n",
    "\n",
    "naive_bayes.fit(train_data_tfidf, [y for x, y in train_data_x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "it does not have 5 stars       0.77      0.93      0.84    285795\n",
      "          it has 5 stars       0.87      0.63      0.73    214205\n",
      "\n",
      "             avg / total       0.81      0.80      0.79    500000\n",
      "\n",
      "\n",
      "Dev-test Data\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "it does not have 5 stars       0.75      0.92      0.83      5725\n",
      "          it has 5 stars       0.85      0.59      0.70      4275\n",
      "\n",
      "             avg / total       0.79      0.78      0.77     10000\n",
      "\n",
      "\n",
      "Test Data\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "it does not have 5 stars       0.75      0.92      0.83      5676\n",
      "          it has 5 stars       0.85      0.60      0.71      4324\n",
      "\n",
      "             avg / total       0.80      0.78      0.78     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "predictions_train = naive_bayes.predict(train_data_tfidf)\n",
    "predictions_devtest = naive_bayes.predict(devtest_data_tfidf)\n",
    "predictions_test = naive_bayes.predict(test_data_tfidf)\n",
    "\n",
    "print(\"Train Data\")\n",
    "print(classification_report([y for x, y in train_data_x], predictions_train))\n",
    "print(\"\\nDev-test Data\")\n",
    "print(classification_report([y for x, y in devtest_data_x], predictions_devtest))\n",
    "print(\"\\nTest Data\")\n",
    "print(classification_report([y for x, y in test_data_x], predictions_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3\n",
    "Logistic regression normally produces better results than Naive Bayes but it takes longer time to train. We can look at the [documentation of sklearn](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) and train a logistic regression classifier using the same tfidf information as in step 2. Report the F1 scores of the training set, the devtest set, and the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic_reg = LogisticRegression()\n",
    "\n",
    "logistic_reg.fit(train_data_tfidf, [y for x, y in train_data_x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "it does not have 5 stars       0.86      0.87      0.87    285795\n",
      "          it has 5 stars       0.83      0.82      0.82    214205\n",
      "\n",
      "             avg / total       0.85      0.85      0.85    500000\n",
      "\n",
      "\n",
      "Dev-test Data\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "it does not have 5 stars       0.85      0.86      0.85      5725\n",
      "          it has 5 stars       0.81      0.79      0.80      4275\n",
      "\n",
      "             avg / total       0.83      0.83      0.83     10000\n",
      "\n",
      "\n",
      "Test Data\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "it does not have 5 stars       0.85      0.87      0.86      5676\n",
      "          it has 5 stars       0.82      0.80      0.81      4324\n",
      "\n",
      "             avg / total       0.84      0.84      0.84     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_train =  logistic_reg.predict(train_data_tfidf)\n",
    "pred_devtest =  logistic_reg.predict(devtest_data_tfidf)\n",
    "pred_test =  logistic_reg.predict(test_data_tfidf)\n",
    "\n",
    "print(\"Train Data\")\n",
    "print(classification_report([y for x, y in train_data_x], pred_train))\n",
    "print(\"\\nDev-test Data\")\n",
    "print(classification_report([y for x, y in devtest_data_x], pred_devtest))\n",
    "print(\"\\nTest Data\")\n",
    "print(classification_report([y for x, y in test_data_x], pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4\n",
    "A piece of code that counts the false positives and false negatives of the training set of each classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fpfn(actual, predict):\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    count = 0\n",
    "    for x in actual:\n",
    "        if x == \"it does not have 5 stars\" and predict[count] == \"it has 5 stars\":\n",
    "            FP += 1\n",
    "        if x == \"it has 5 stars\" and predict[count] == \"it does not have 5 stars\":\n",
    "            FN += 1\n",
    "        count += 1\n",
    "\n",
    "    return(FP, FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False Positive: 20742\n",
      "False Negative: 79299\n",
      "\n",
      "False Positive: 35875\n",
      "False Negative: 39162\n"
     ]
    }
   ],
   "source": [
    "print(\"False Positive: \"+str(calculate_fpfn([y for x,y in train_data_x], naive_bayes.predict(train_data_tfidf))[0]))\n",
    "print(\"False Negative: \"+str(calculate_fpfn([y for x,y in train_data_x], naive_bayes.predict(train_data_tfidf))[1]))\n",
    "print()\n",
    "print(\"False Positive: \"+str(calculate_fpfn([y for x,y in train_data_x], logistic_reg.predict(train_data_tfidf))[0]))\n",
    "print(\"False Negative: \"+str(calculate_fpfn([y for x,y in train_data_x], logistic_reg.predict(train_data_tfidf))[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Logistic Regression predicts better than Naive Bayes. There is huge difference in terms of False Negative. Though in both case, the amount of False Negative is higher than the amount of False Positive. It's because in our Train-set, there are differences in ratio between positive and negative reviews. So the classifier is getting more biased towards one side. </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of errors: 2183\n",
      "\n",
      "Prediction: \n",
      "it does not have 5 stars\n",
      "\n",
      "Actual: \n",
      "it has 5 stars\n",
      "I went to B&R with two coworkers who were visiting from another country.  We shared some appetizers (Tartar, Brussel Sprouts, Trio of Crostini), we each ordered an entree and a dessert.  Overall, an excellent experience.  The food was very good and I loved the cocktails.\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Prediction: \n",
      "it does not have 5 stars\n",
      "\n",
      "Actual: \n",
      "it has 5 stars\n",
      "Visited Monday 11\\/9 because I had won a $20 gift certificate in a golf tournament.  Not knowing anything about the place, we were pleasantly surprised at the cleanliness of the bar\\/restaurant.  There were a few people out on the patio (smokers, kind of a turnoff) but we were planning on sitting inside anyhow.  The bartender\\/waitress was very friendly and attentive, which is always good!  We split a personal pizza, a salad and a Philly cheese steak sandwich. We got the thin crust pizza and I highly recommend you try it and it was cooked perfectly.  The Philly had a heap of meat on it and the roll it was served on was fresh and just really good.  The salad was also very fresh and they have really good Ranch dressing (and I am a Ranch snob!)  So, I would say this is better than just \"bar food\" it seems to be teetering on fresh ingredients and someone in the back does care about what they are doing.  I will be back for lunch and or dinner soon.\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Prediction: \n",
      "it has 5 stars\n",
      "\n",
      "Actual: \n",
      "it does not have 5 stars\n",
      "Fast, clean and gorgeous work done by friendly staff. If I lived in town, this would be my spot.\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Prediction: \n",
      "it does not have 5 stars\n",
      "\n",
      "Actual: \n",
      "it has 5 stars\n",
      "We visited the Grand View buffet early in the evening, so it was not very crowded when we arrived. However, the dining room became quite busy later on. A buy-one-get-one free special was available on week days in January, making it quite affordable. We got two buffets for $20, along with nonalcoholic beverages that were included in the price! \n",
      "\n",
      "We were greeted upon arrival and were seated immediately. Our server was quite pleasant and efficient. She provided drink refills and cleared our table as needed. Employees at the various stations were also quite pleasant. They keep all food items well stocked throughout the evening. The view of the river from the large picture windows was an added bonus. \n",
      "\n",
      "There were various food stations available, including Asian (with stir-fried items which you select and have prepared while you wait), Italian, American, and BBQ. A large salad bar offered a variety of fresh salad items, along with soups and rolls. A carving station offered deliciously tender prime rib, as well as ham and turkey. The dessert station had a large variety of desserts attractively presented, with one dessert being served in small, plastic martini glasses. Several sugar-free desserts were also available, along with a nice variety of gelato. \n",
      "\n",
      "We thoroughly enjoyed our meals and look forward to eating here again in the near future.\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Prediction: \n",
      "it does not have 5 stars\n",
      "\n",
      "Actual: \n",
      "it has 5 stars\n",
      "The food in this place is ridiculously delicious! Everything is fresh and succulent. Thank you wok of fame for bringing your food to Ontario. I hope that other buffet restaurants will step up to the plate like wok of fame. Their grilled items, sashimi, miso soup, sundae and many more are the ones to die for.\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Prediction: \n",
      "it has 5 stars\n",
      "\n",
      "Actual: \n",
      "it does not have 5 stars\n",
      "My husband and I found this place through Groupon and are very glad we did!  We ordered some of the chef special rolls and they were phenomenal!  Really good.  Portions were big without overloading with rice!  We'll definately be going back!\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n",
      "Prediction: \n",
      "it does not have 5 stars\n",
      "\n",
      "Actual: \n",
      "it has 5 stars\n",
      "If you want REAL coffee and no watery a** Starbucks...go here! They have their own coffee plantation in Brazil I believe that they import from, so there is that. Amazing quality.\n",
      "\n",
      "-----------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "error_count = 0\n",
    "for x in range(0, len(devtest_data_x)-1):\n",
    "    if (naive_bayes.predict(devtest_data_tfidf)[x]!=devtest_data_x[x][1]):\n",
    "        error_count += 1\n",
    "print(\"Number of errors: \" +str(error_count))\n",
    "print()\n",
    "for x in range(0, 20):\n",
    "    if (naive_bayes.predict(devtest_data_tfidf)[x]!=devtest_data_x[x][1]):\n",
    "        print(\"Prediction: \")\n",
    "        print(naive_bayes.predict(devtest_data_tfidf)[x])\n",
    "        print()\n",
    "        print(\"Actual: \")\n",
    "        print(devtest_data_x[x][1])\n",
    "        print(devtest_data_x[x][0])\n",
    "        print()\n",
    "        print('-----------------------------------------------------------')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>We are analysing first 21 reviews from the Dev-test set. The classifier mostly matching the pattern of the sentences from Train data set to predict the result. It's calculating according to the word repetition. We are passing the whole review without cleaning words. So it’s predicting without thinking about any positive or negative words. Unimportant words are being taken into consideration for the prediction. Also, we are providing different ratio of positive and negative review, which is making the classifier biased towards one category over other.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation of the Proposed New Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Improved classifier should clean the words list first, which will make the list more readable. Then there will be a list of bag of words, which will store all the vocabulary from the data set. Then we will train the new classifier with the bag of words. Then the classifier will predict from the base of bag of words. Hence, the clean more readable words instead of the whole sentence and the bag of words will bring better match and better prediction.Also, training the classifier with same ratio of positive and negative review will impore the prediction quality.</b>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
